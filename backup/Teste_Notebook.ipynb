{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import Classificador_kseg_new as kseg\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(y, yp, CP):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    if CP == True:\n",
    "        N_inl = len(np.where(y == 0)[0])\n",
    "        N_out = len(y) - N_inl\n",
    "        \n",
    "        #inlier\n",
    "        tp, fn, fp, tn = confusion_matrix(y, yp).ravel()\n",
    "        prec_inl = tp/(tp + fp)\n",
    "        rec_inl = tp/(tp + fn)\n",
    "        f1_inl = 2*((prec_inl * rec_inl)/(prec_inl + rec_inl))    \n",
    "        #outlier\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yp).ravel()\n",
    "        prec_out = tp/(tp + fp)\n",
    "        rec_out = tp/(tp + fn)\n",
    "        f1_out = 2*((prec_out * rec_out)/(prec_out + rec_out))\n",
    "    \n",
    "    else:\n",
    "        N_inl = len(np.where(y == 1)[0])\n",
    "        N_out = len(y) - N_inl\n",
    "        \n",
    "        #inlier\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yp).ravel()\n",
    "        prec_inl = tp/(tp + fp)\n",
    "        rec_inl = tp/(tp + fn)\n",
    "        f1_inl = 2*((prec_inl * rec_inl)/(prec_inl + rec_inl))\n",
    "        #outlier\n",
    "        tp, fn, fp, tn = confusion_matrix(y, yp).ravel()\n",
    "        prec_out = tp/(tp + fp)\n",
    "        rec_out = tp/(tp + fn)\n",
    "        f1_out = 2*((prec_out * rec_out)/(prec_out + rec_out))    \n",
    "    \n",
    "    f1 = (f1_inl*N_inl + f1_out*N_out)/(N_inl + N_out)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    return prec_inl, rec_inl, prec_out, rec_out, f1_inl, f1_out, f1, acc\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaROC(model, CP, Xst, Xf):\n",
    "    \n",
    "    if (CP == True):\n",
    "        \n",
    "        e = model['edges']\n",
    "        v = model['vertices']\n",
    "    \n",
    "        from copy import copy\n",
    "        ii, dn = kseg.Kseg_new.map_to_arcl(copy(e),copy(v),Xst)\n",
    "        ii, dp = kseg.Kseg_new.map_to_arcl(copy(e),copy(v),Xf)\n",
    "        del ii \n",
    "        y_pred = np.concatenate((dn, dp), axis = 0)\n",
    "        y  = np.concatenate((np.zeros(Xst.shape[0]), np.ones(Xf.shape[0])), axis = 0)\n",
    "    ##\n",
    "    else:\n",
    "        Xt = np.concatenate((Xst, Xf), axis = 0)\n",
    "        y_pred = model.score_samples(Xt)\n",
    "        y  = np.concatenate((np.ones(Xst.shape[0]), np.zeros(Xf.shape[0])), axis = 0)\n",
    "    ##\n",
    "    \n",
    "        \n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y,y_pred)\n",
    "    \n",
    "    return fpr, tpr, threshold\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geraROC(tpr_t, fpr_t, name):\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    from sklearn import metrics\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Random', alpha=.8)\n",
    "    \n",
    "    for key in tpr_t:\n",
    "        tpr = tpr_t[key]\n",
    "        fpr = fpr_t[key]\n",
    "        for i in range(len(tpr)):\n",
    "            auc = metrics.auc(tpr[i], fpr[i])\n",
    "            aucs.append(auc)\n",
    "            \n",
    "            interp_tpr = np.interp(mean_fpr, fpr[i], tpr[i])\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "        \n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        \n",
    "        mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        ax.plot(mean_fpr, mean_tpr, \n",
    "            label=r'Mean ROC %s (AUC = %0.2f $\\pm$ %0.2f)' % (key, mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "    \n",
    "        # std_tpr = np.std(tprs, axis=0)\n",
    "        # tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        # tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        # ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "        #                 label=r'$\\pm$ 1 std. dev.')\n",
    "        means.update({key: mean_auc})\n",
    "        stds.update({key: std_auc})\n",
    "        \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "        title=\"Mean ROC Curve \" + name, xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\")\n",
    "        \n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return means, stds\n",
    "    \n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando e manipulando dataset\n",
    "# dataset_name = 'Credit Card Fraud Detection'\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('C:/Users/Fernando Elias/Documents/Datasets/310_23498_bundle_archive/creditcard.csv')\n",
    "# X = df.to_numpy()\n",
    "\n",
    "\n",
    "dataset_name = 'Mammography'\n",
    "import scipy.io as sio \n",
    "df = sio.loadmat('mammography.mat')\n",
    "df_x = df['X']\n",
    "df_y = df['y']\n",
    "X = np.concatenate((df_x, df_y), axis = 1)\n",
    "\n",
    "# dataset_name = 'MNIST'\n",
    "# import scipy.io as sio \n",
    "# df = sio.loadmat('mnist.mat')\n",
    "# df_x = df['X']\n",
    "# df_y = df['y']\n",
    "# X = np.concatenate((df_x, df_y), axis = 1)\n",
    "\n",
    "# dataset_name = 'Breast Cancer Wisconsin'\n",
    "# import scipy.io as sio \n",
    "# df = sio.loadmat('breastw.mat')\n",
    "# df_x = df['X']\n",
    "# df_y = df['y']\n",
    "# X = np.concatenate((df_x, df_y), axis = 1)\n",
    "\n",
    "# dataset_name = 'annthyroid dataset'\n",
    "# import scipy.io as sio \n",
    "# df = sio.loadmat('annthyroid.mat')\n",
    "# df_x = df['X']\n",
    "# df_y = df['y']\n",
    "# X = np.concatenate((df_x, df_y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tamanho do conj. de treino e numero de execuções\n",
    "vezes = 5\n",
    "save = False\n",
    "\n",
    "CP = True\n",
    "IFO = True\n",
    "SVM = True\n",
    "\n",
    "\n",
    "\n",
    "ii = np.where(X[:,-1] == 1)\n",
    "ii = ii[0]\n",
    "\n",
    "Xfi = X[np.where(X[:,-1] == 1)]\n",
    "Xs = X[np.where(X[:,-1] == 0)]\n",
    "\n",
    "Xs = np.delete(Xs, np.s_[0:1], axis = 1)\n",
    "Xfi = np.delete(Xfi, np.s_[0:1], axis = 1)\n",
    "Xs = np.delete(Xs, np.s_[Xs.shape[1]-1:Xs.shape[1]], axis = 1)\n",
    "Xfi = np.delete(Xfi, np.s_[Xfi.shape[1]-1:Xfi.shape[1]], axis = 1)\n",
    "\n",
    "#Determinando tamanho do conjunto de treino:\n",
    "Nt = int(0.7*Xs.shape[0])\n",
    "\n",
    "#parametros de desempenho:\n",
    "accSF_treino = np.zeros((vezes,3))\n",
    "accSF_teste = np.zeros((vezes,3))\n",
    "accFF_teste = np.zeros((vezes,3))\n",
    "\n",
    "tprs_CP = []; fprs_CP = []; thresholds_CP = []\n",
    "prec_inl_CP = []; rec_inl_CP = []; f1_inl_CP = []; acc_CP = []\n",
    "prec_out_CP = []; rec_out_CP = []; f1_out_CP = []; f1_CP =  []\n",
    "time_CP = []\n",
    "\n",
    "tprs_IFO = []; fprs_IFO = []; thresholds_IFO = []\n",
    "prec_inl_IFO = []; rec_inl_IFO = []; f1_inl_IFO = []; acc_IFO = [] \n",
    "prec_out_IFO = []; rec_out_IFO = []; f1_out_IFO = []; f1_IFO  = []\n",
    "time_IFO = []\n",
    "\n",
    "tprs_SVM = []; fprs_SVM = []; thresholds_SVM = []\n",
    "prec_inl_SVM = []; rec_inl_SVM = []; f1_inl_SVM = []; acc_SVM = [] \n",
    "prec_out_SVM = []; rec_out_SVM = []; f1_out_SVM = []; f1_SVM  = []\n",
    "time_SVM = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#CP params:\n",
    "k_segs = 10; outl = 0.15\n",
    "\n",
    "#IFO params:\n",
    "cont = 0.29\n",
    "\n",
    "#OC-SVM params:\n",
    "nu_ = 0.3\n",
    "\n",
    "\n",
    "\n",
    "for z in range(0, vezes):\n",
    "    \n",
    "    print('iteration number: ', z+1)\n",
    "    for i in range(5):\n",
    "        np.random.shuffle(Xs)\n",
    "    \n",
    "    Xspi = Xs[0:Nt, :]\n",
    "    scaler.fit(Xspi)\n",
    "    Xsp = scaler.transform(Xspi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Xsti = Xs[Nt:, :]\n",
    "    Xst = scaler.transform(Xsti)\n",
    "    \n",
    "    Xf  = scaler.transform(Xfi)\n",
    "    # #CP\n",
    "    if(CP):\n",
    "        ini = time.time()\n",
    "        param = kseg.unsupervised_ksegFit(X_train, k_segs, 1, 1, outl, 1000) \n",
    "        fim = time.time()\n",
    "        time_CP.append(fim-ini)\n",
    "        uu, accSF_treino[z, 0] = kseg.unsupervised_ksegPredict(param, Xsp, np.zeros(Xsp.shape[0]))\n",
    "        uu1, accSF_teste[z, 0]  = kseg.unsupervised_ksegPredict(param, Xst, np.zeros(Xst.shape[0]))\n",
    "        uu2, accFF_teste[z, 0]  = kseg.unsupervised_ksegPredict(param, Xf, np.ones(Xf.shape[0]))\n",
    "        fpr, tpr, threshold = calculaROC(param, True, Xst, Xf)\n",
    "        tprs_CP.append(tpr); fprs_CP.append(fpr); thresholds_CP.append(threshold)   \n",
    "\n",
    "        prec_inl, rec_inl, prec_out, rec_out, f1_inl, f1_out, f1, acc = getResults(\n",
    "            np.concatenate((np.zeros(Xst.shape[0]), np.ones(Xf.shape[0])), axis = 0), \n",
    "            np.concatenate((uu1, uu2)), True)\n",
    "\n",
    "        prec_inl_CP.append(prec_inl); rec_inl_CP.append(rec_inl); f1_inl_CP.append(f1_inl); acc_CP.append(acc)\n",
    "        prec_out_CP.append(prec_out); rec_out_CP.append(rec_out); f1_out_CP.append(f1_out); f1_CP.append(f1)\n",
    "    \n",
    "    #Isolation Forest\n",
    "    if(IFO):\n",
    "        ini = time.time()\n",
    "        rng = np.random.RandomState(42)\n",
    "        clf_IFO = IsolationForest(n_estimators = 100, max_samples=100,\n",
    "                           random_state=rng, contamination=cont).fit(Xsp)\n",
    "\n",
    "        fim = time.time()\n",
    "        time_IFO.append(fim-ini)\n",
    "        fpr, tpr, threshold = calculaROC(clf_IFO, False, Xst, Xf)\n",
    "        tprs_IFO.append(tpr); fprs_IFO.append(fpr); thresholds_IFO.append(threshold)  \n",
    "\n",
    "        prec_inl, rec_inl, prec_out, rec_out, f1_inl, f1_out, f1, acc = getResults(\n",
    "            np.concatenate((np.ones(Xst.shape[0]), -1*np.ones(Xf.shape[0])), axis = 0), \n",
    "            np.concatenate((clf_IFO.predict(Xst), clf_IFO.predict(Xf))), False)\n",
    "\n",
    "        prec_inl_IFO.append(prec_inl); rec_inl_IFO.append(rec_inl); f1_inl_IFO.append(f1_inl); acc_IFO.append(acc)\n",
    "        prec_out_IFO.append(prec_out); rec_out_IFO.append(rec_out); f1_out_IFO.append(f1_out); f1_IFO.append(f1)\n",
    "\n",
    "    #OC-SVM\n",
    "    if(SVM):\n",
    "        ini = time.time()\n",
    "        clf_SVM = OneClassSVM(gamma='auto', nu = nu_).fit(Xsp)\n",
    "        fim = time.time()\n",
    "        time_SVM.append(fim-ini)\n",
    "\n",
    "        fpr, tpr, threshold = calculaROC(clf_SVM, False, Xst, Xf)\n",
    "        tprs_SVM.append(tpr); fprs_SVM.append(fpr); thresholds_SVM.append(threshold)  \n",
    "\n",
    "        prec_inl, rec_inl, prec_out, rec_out, f1_inl, f1_out, f1, acc = getResults(\n",
    "            np.concatenate((np.ones(Xst.shape[0]), -1*np.ones(Xf.shape[0])), axis = 0), \n",
    "            np.concatenate((clf_SVM.predict(Xst), clf_SVM.predict(Xf))), False)\n",
    "\n",
    "        prec_inl_SVM.append(prec_inl); rec_inl_SVM.append(rec_inl); f1_inl_SVM.append(f1_inl); acc_SVM.append(acc)\n",
    "        prec_out_SVM.append(prec_out); rec_out_SVM.append(rec_out); f1_out_SVM.append(f1_out); f1_SVM.append(f1)\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(CP == IFO == SVM):\n",
    "    fprs_total = {'Principal Curves': fprs_CP, 'Isolation Forest': fprs_IFO, 'One-Class SVM': fprs_SVM}\n",
    "    tprs_total = {'Principal Curves': tprs_CP, 'Isolation Forest': tprs_IFO, 'One-Class SVM': tprs_SVM}\n",
    "    means_auc, stds_auc = geraROC(tprs_total, fprs_total, dataset_name)\n",
    "    auc_CP =  [means_auc['Principal Curves'], stds_auc['Principal Curves']]\n",
    "    auc_IFO = [means_auc['Isolation Forest'], stds_auc['Isolation Forest']]\n",
    "    auc_SVM = [means_auc['One-Class SVM'], stds_auc['One-Class SVM']]\n",
    "    \n",
    "elif(CP):\n",
    "    fprs_total = {'Principal Curves': fprs_CP}\n",
    "    tprs_total = {'Principal Curves': tprs_CP}\n",
    "    means_auc, stds_auc = geraROC(tprs_total, fprs_total, dataset_name)\n",
    "    auc_CP =  [means_auc['Principal Curves'], stds_auc['Principal Curves']]\n",
    "\n",
    "elif(IFO):\n",
    "    fprs_total = {'Isolation Forest': fprs_IFO}\n",
    "    tprs_total = {'Isolation Forest': tprs_IFO}\n",
    "    means_auc, stds_auc = geraROC(tprs_total, fprs_total, dataset_name)\n",
    "    auc_IFO = [means_auc['Isolation Forest'], stds_auc['Isolation Forest']]\n",
    "\n",
    "elif(SVM):\n",
    "    fprs_total = {'One-Class SVM': fprs_SVM}\n",
    "    tprs_total = {'One-Class SVM': tprs_SVM}\n",
    "    means_auc, stds_auc = geraROC(tprs_total, fprs_total, dataset_name)\n",
    "    auc_SVM = [means_auc['One-Class SVM'], stds_auc['One-Class SVM']]\n",
    "\n",
    "\n",
    "def exibe(CP, IFO, SVM):\n",
    "    \n",
    "    if(CP):\n",
    "        print(\"\\nPrincipal Curves:\")\n",
    "        print('Treino ACC:     ''%.2f' %(np.mean(accSF_treino[:,0])*100),'%.2f' %(np.std(accSF_treino[:,0])*100))\n",
    "        print(\"----- teste ------\")\n",
    "        print('Recall InLier:     ''%.2f' %((np.mean(rec_inl_CP))*100),'%.2f' %((np.std(rec_inl_CP))*100))\n",
    "        print('Recall OutLier:    ''%.2f' %((np.mean(rec_out_CP))*100),'%.2f' %((np.std(rec_out_CP))*100))\n",
    "        print('F1-Score InLier:   ''%.2f' %((np.mean(f1_inl_CP))*100),'%.2f' %((np.std(f1_inl_CP))*100))\n",
    "        print('F1-Score OutLier:  ''%.2f' %((np.mean(f1_out_CP))*100),'%.2f' %((np.std(f1_out_CP))*100))\n",
    "        print('F1-Score Model:    ''%.2f' %((np.mean(f1_CP))*100),'%.2f' %((np.std(f1_CP))*100))\n",
    "        print('ACC Model:         ''%.2f' %((np.mean(acc_CP))*100),'%.2f' %((np.std(acc_CP))*100))\n",
    "        print('AUC Model:         ''%.2f' %(auc_CP[0]*100),'%.2f' %(auc_CP[1]*100))\n",
    "        print('Time:              ''%.2f' %((np.mean(time_CP))),'%.2f' %((np.std(time_CP))))\n",
    "    \n",
    "    if(IFO):\n",
    "        print(\"\\nIsolation Forest:\")\n",
    "        print('Treino ACC:     ''%.2f' %(np.mean(accSF_treino[:,1])*100),'%.2f' %(np.std(accSF_treino[:,1])*100))\n",
    "        print(\"----- teste ------\")\n",
    "        print('Recall InLier:     ''%.2f' %((np.mean(rec_inl_IFO))*100),'%.2f' %((np.std(rec_inl_IFO))*100))\n",
    "        print('Recall OutLier:    ''%.2f' %((np.mean(rec_out_IFO))*100),'%.2f' %((np.std(rec_out_IFO))*100))\n",
    "        print('F1-Score InLier:   ''%.2f' %((np.mean(f1_inl_IFO))*100),'%.2f' %((np.std(f1_inl_IFO))*100))\n",
    "        print('F1-Score OutLier:  ''%.2f' %((np.mean(f1_out_IFO))*100),'%.2f' %((np.std(f1_out_IFO))*100))\n",
    "        print('F1-Score Model:    ''%.2f' %((np.mean(f1_IFO))*100),'%.2f' %((np.std(f1_IFO))*100))\n",
    "        print('ACC Model:         ''%.2f' %((np.mean(acc_IFO))*100),'%.2f' %((np.std(acc_IFO))*100))\n",
    "        print('AUC Model:         ''%.2f' %(auc_IFO[0]*100),'%.2f' %(auc_IFO[1]*100))\n",
    "        print('Time:              ''%.2f' %((np.mean(time_IFO))),'%.2f' %((np.std(time_IFO))))\n",
    "    \n",
    "    if(SVM): \n",
    "        print(\"\\nOne-Class SVM:\")\n",
    "        print('Treino ACC:     ''%.2f' %(np.mean(accSF_treino[:,2])*100),'%.2f' %(np.std(accSF_treino[:,2])*100))\n",
    "        print(\"----- teste ------\")\n",
    "        print('Recall InLier:     ''%.2f' %((np.mean(rec_inl_SVM))*100),'%.2f' %((np.std(rec_inl_SVM))*100))\n",
    "        print('Recall OutLier:    ''%.2f' %((np.mean(rec_out_SVM))*100),'%.2f' %((np.std(rec_out_SVM))*100))\n",
    "        print('F1-Score InLier:   ''%.2f' %((np.mean(f1_inl_SVM))*100),'%.2f' %((np.std(f1_inl_SVM))*100))\n",
    "        print('F1-Score OutLier:  ''%.2f' %((np.mean(f1_out_SVM))*100),'%.2f' %((np.std(f1_out_SVM))*100))\n",
    "        print('F1-Score Model:    ''%.2f' %((np.mean(f1_SVM))*100),'%.2f' %((np.std(f1_SVM))*100))\n",
    "        print('ACC Model:         ''%.2f' %((np.mean(acc_SVM))*100),'%.2f' %((np.std(acc_SVM))*100))\n",
    "        print('AUC Model:         ''%.2f' %(auc_SVM[0]*100),'%.2f' %(auc_SVM[1]*100))\n",
    "        print('Time:              ''%.2f' %((np.mean(time_SVM))),'%.2f' %((np.std(time_SVM))))\n",
    "\n",
    "##\n",
    "\n",
    "exibe(CP, IFO, SVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
